# ===== Snake file for processing Bowtie ================================

# Configure shell for all rules
shell.executable("/bin/bash")
shell.prefix("source ~/.bash_profile; set -o nounset -o pipefail -o errexit -x; ")

# python packages
import os
import sys
import yaml
from pathlib import Path

# Include custom Python functions
include: "funs.py"

# ------------------------------------------------------------------------------
# Load main genome config
# ------------------------------------------------------------------------------

GENOME = config["GENOME"]
GENOME_CONFIG = Path("pipelines/ref") / f"{GENOME}.yaml"

if not GENOME_CONFIG.exists():
    sys.exit(f"ERROR: {GENOME} is not a valid GENOME selection.")

# Load the main config file into Snakemake's config dictionary
configfile: str(GENOME_CONFIG)

# ------------------------------------------------------------------------------
# Load additional genome-specific configs manually
# ------------------------------------------------------------------------------

INDEXES = config['INDEXES']
if isinstance(INDEXES, str):
    INDEXES = [INDEXES]

# Load genome-specific config files into a dictionary
config_indexes = {}
for idx in INDEXES:
    path = Path("pipelines/ref") / f"{idx}.yaml"
    if not path.exists():
        sys.exit(f"ERROR: {idx} is not a valid genome index.")
    with open(path) as f:
        config_indexes[idx] = yaml.safe_load(f)


# ------------------------------------------------------------------------------
# Assign parameters from configs
# ------------------------------------------------------------------------------

# From main config
PROJ         = config.get("PROJ")
RAW_DATA     = config.get("RAW_DATA")
ALL_SAMPLES  = config.get("SAMPLES")
SEQ_DATE     = config.get("SEQ_DATE")
BARCODES     = config.get("BARCODES")
INDEX_PATH   = config.get("INDEX_PATH")
INDEX_MAP    = config.get("INDEX_MAP")
CMD_PARAMS   = config.get("CMD_PARAMS")
NORM         = config.get('NORM')
COLORS       = config.get("COLORS")
ORIENTATION  = config.get("ORIENTATION")
USER         = config.get("USER")

# Directories for data and scripts
FASTQ_DIR = PROJ + "/fastqs"

os.makedirs(FASTQ_DIR, exist_ok = True)

def get_orientation(orientation):
    if orientation == "R1R2":
        return "R1"
    elif orientation == "R2R1":
        return "R2"
    return orientation

ORIENTATION = get_orientation(ORIENTATION)

# Simplify ALL_SAMPLES dictionary
SAMPLES, SAMPIN, GROUPS, NORMMAP, PAIREDMAP = process_samples(
    ALL_SAMPLES, INDEXES, NORM, ORIENTATION
)

# make file suffix from bamCoverage settings and NORM 
for sample, norm_list in NORMMAP.items():
    updated_list = [
        (index, norm_value, _get_normtype(
            CMD_PARAMS["bamCoverage"],
            norm_value,
            CMD_PARAMS.get("bamCoverageBL", ""),
            ORIENTATION
        ))
        for index, norm_value in norm_list
    ]
    NORMMAP[sample] = updated_list
    
# Combine into a list of records with expanded NormMap
SAM_NORM = []
for key in SAMPIN:
    sam_value = SAMPIN[key][0]
    for index, norm, suffix in NORMMAP[key]:
        SAM_NORM.append([sam_value, key, index, norm, suffix])

# Create DataFrame
DF_SAM_NORM = pd.DataFrame(SAM_NORM, columns=['Sample', 'Newnam', 'Index', 'Norm', 'Suffix'])

# unpack samples and groups
SAMS = [[y, x] for y in SAMPIN for x in SAMPIN[y]]
NAMS = [x[0] for x in SAMS] # newnames
SAMS = [x[1] for x in SAMS] # samples
GRPS = [[y, x] for y in GROUPS for x in GROUPS[y]]
GRPS = [x[0] for x in GRPS] # groups
NAMS_UNIQ = list(dict.fromkeys(NAMS))
GRPS_UNIQ = list(dict.fromkeys(GRPS))
SAMS_UNIQ = list(dict.fromkeys(SAMS))

# Print summary of samples and groups
print("SAMPLES (%s): %s\n" % (len(SAMPLES), SAMPLES))
print("GROUPS (%s): %s\n" % (len(GROUPS), GROUPS))
print("SAMPIN (%s): %s\n" % (len(SAMPIN), SAMPIN))
print("SAMS_UNIQ (%s): %s\n" % (len(SAMS_UNIQ), SAMS_UNIQ))
print("NAMS_UNIQ (%s): %s\n" % (len(NAMS_UNIQ), NAMS_UNIQ))
print("GRPS_UNIQ (%s): %s\n" % (len(GRPS_UNIQ), GRPS_UNIQ))
print("NORMMAP (%s): %s\n" % (len(NORMMAP), NORMMAP))
print("PAIREDMAP (%s): %s\n" % (len(PAIREDMAP), PAIREDMAP))
print(DF_SAM_NORM.to_string(index=False))

# Wildcard constraints
WILDCARD_REGEX = "[a-zA-Z0-9_\-]+" # Matches alphanumeric characters, underscores, and hyphens

wildcard_constraints:
    sample = WILDCARD_REGEX,
    newnam = WILDCARD_REGEX,
    group  = WILDCARD_REGEX,
    index  = WILDCARD_REGEX,
    suffix = WILDCARD_REGEX   

# Create symlinks for fastqs
FASTQS = [_get_fqs(x, RAW_DATA, FASTQ_DIR, paired=True) for x in SAMS_UNIQ]
FASTQS = sum(FASTQS, [])

COLS_DICT = _get_colors(NAMS_UNIQ, COLORS)

NORMS = _get_normtype(CMD_PARAMS["bamCoverage"],NORM,CMD_PARAMS.get("bamCoverageBL", ""),ORIENTATION)

BAM_PATH = _get_bampath(NORM)
ALIGNER = "bowtie2"


# Final output files
rule all:
    input:
        # process summary files
        expand("{proj}/stats/{proj}_{step}.tsv", proj=PROJ, step=["fastqc", "cutadapt", "aligned"]),
        
        # bam URL
        #expand(PROJ + "/URLS/" + PROJ + "_{index}_bam_URL.txt", index=INDEXES),
        
        # subsample of all reads, and URL's
        #expand(PROJ + "/URLS/" + PROJ + "_{index}_subsample_bam_URL.txt", index=INDEXES),
        
        # results
        expand(
          PROJ + "/report/" + PROJ + "_{index}_fragmentSize.pdf", 
          index=INDEXES
        ),
        #expand(PROJ + "/report/{index}_PCA.png", index=INDEXES),
        PROJ + "/report/" + PROJ + "_results.tsv",
        
        # bamCoverage URL
        expand(
          PROJ + "/URLS/" + PROJ + "_{index}_" + SEQ_DATE + "_norm_{suffix}_bw_URL.txt",
           zip, index=DF_SAM_NORM['Index'], suffix=DF_SAM_NORM['Suffix']
        )


# Run FastQC
include: "rules/01_fastqc.snake"
# Run cutadapt
include: "rules/01_UMI_cutadapt.snake"
# Align reads 
include: "rules/02a_align_bowtie.snake"
include: "rules/02b_align_UMI_samtools.snake"
include: "rules/02c_align_URLS.snake"
include: "rules/02s_align_mask_subsample.snake"
# Results
include: "rules/03a_featureCounts.snake"
include: "rules/03a_fragmentSize.snake"
include: "rules/03b_results_UMI.snake"
include: "rules/03b_PCAplot.snake"
# BW with deeptools bamCoverage
include: "rules/04_bamCoverage_stranded.snake"


