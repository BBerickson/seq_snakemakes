# ===== Snake file for processing mNET-seq data ================================

from pytools.persistent_dict import PersistentDict
import os
import glob
import re
import subprocess
import gzip
import random


# Configure shell for all rules
shell.executable("/bin/bash")
shell.prefix("source ~/.bash_profile; set -o nounset -o pipefail -o errexit -x; ")


# Parameters from config.yaml
PROJ            = config["PROJ"]
SAMPLES         = config["SAMPLES"]
SEQ_DATE        = config["SEQ_DATE"]
INDEX_PATH      = config["INDEX_PATH"]
INDEX_MAP       = config["INDEX_MAP"]
INDEX_SAMPLE    = config["INDEX_SAMPLE"]
INDEX_SPIKE     = ""
FW_REF          = config["FW_REF"]
REV_REF         = config["REV_REF"]
CMD_PARAMS      = config["CMD_PARAMS"]
COLORS          = config["COLORS"]
NORM            = config["NORM"]
USER            = config["USER"]
GENELIST        = config["GENELIST"]
MEMORY          = config["MEMORY"]

# Sample and group lists
SAMS = [[y, x] for y in SAMPLES for x in SAMPLES[y]]
GRPS = [x[1] for x in SAMS] # no nicknames 
GRP2 = [x[0] for x in SAMS]
SAMS = [x[1] for x in SAMS]

GRPS_UNIQ = list(dict.fromkeys(GRPS))
GRP2_UNIQ = list(dict.fromkeys(GRP2))
SAMS_UNIQ = list(dict.fromkeys(SAMS))
SAMS_UNIQ2 = list(dict.fromkeys(SAMS[::2]))

# Print summary of samples and groups
print("SAMS (%s): %s\n" % (len(SAMS), SAMS))
print("GRPS (%s): %s\n" % (len(GRPS), GRPS))
print("SAMS_UNIQ (%s): %s\n" % (len(SAMS_UNIQ), SAMS_UNIQ))
print("GRP2_UNIQ (%s): %s\n" % (len(GRP2_UNIQ), GRP2_UNIQ))
print("SAMS_UNIQ2 (%s): %s\n" % (len(SAMS_UNIQ2), SAMS_UNIQ2))

# Wildcard constraints
GRP_REGEX = "[a-zA-Z0-9_\-]+"

wildcard_constraints:
    sample  = "[a-zA-Z0-9_\-]+",
    group   = GRP_REGEX,
    sam_grp = "[a-zA-Z0-9_\-]+-[a-zA-Z0-9_\-]+"


def _get_colors(sample_key, color):
    if len(sample_key) >= len(color):
      color.extend(["0,0,0"]*len(set(sample_key)))
    res = {}
    for key in sample_key:
      for value in color:
        res[key] = value
        color.remove(value)
        break  
    return(res)

COLS_DICT = _get_colors(SAMS_UNIQ, COLORS)

def _get_col(wildcards):
    group = wildcards.group
    if group in COLS_DICT:
      results = COLS_DICT[group]
    else:
      results = "0,0,0"
    return(results)

def _rgb2hex(wildcards):
    samples = SAMPLES[wildcards.group2]
    hex_colors = []
    for group in samples:
      if group in COLS_DICT:
        results = COLS_DICT[group]
      else:
        results = "0,0,0"
      myrgb = tuple(map(int, results.split(",")))
      myhex = "#{:02x}{:02x}{:02x}".format(*myrgb)
      hex_colors.append(myhex)
    # Join hex colors with space separator
    hex_colors = hex_colors + hex_colors
    return " ".join(hex_colors)
    
def _rgb2hexplus(wildcards):
    samples = SAMPLES[wildcards.group2]
    hex_colors = []
    hex_colors2 = []
    for group in samples:
      if group in COLS_DICT:
        results = COLS_DICT[group]
      else:
        results = "0,0,0"
      myrgb = tuple(map(int, results.split(",")))
      myhex = "white,#{:02x}{:02x}{:02x}".format(*myrgb)
      myhex2 = "#{:02x}{:02x}{:02x},white".format(*myrgb)
      hex_colors.append(myhex)
      hex_colors2.append(myhex2)
    # Join hex colors with space separator
    hex_colors = hex_colors + hex_colors2
    return " ".join(hex_colors)

def _rgb2hexplus2(wildcards):
    samples = SAMPLES[wildcards.group2]
    hex_colors = []
    hex_colors2 = []
    for group in samples:
      if group in COLS_DICT:
        results = COLS_DICT[group]
      else:
        results = "0,0,0"
      myrgb = tuple(map(int, results.split(",")))
      myhex = "white,#{:02x}{:02x}{:02x}".format(*myrgb)
      myhex2 = "#{:02x}{:02x}{:02x},white".format(*myrgb)
      hex_colors.append(myhex)
      hex_colors2.append(myhex2)
    # Join hex colors with space separator
    hex_colors = hex_colors2 + hex_colors
    return " ".join(hex_colors)
    
def _get_normtype(normUsing, scaleFactor, blacklist):
    if re.search(r"\S", scaleFactor):
        scaleFactor = "_norm_" + scaleFactor
    else:
        scaleFactor = ""
    match = re.search(r"--Offset\s+(-?\d+)", normUsing)
    if match:
      num = int(match.group(1))
      if num == -1:
        word = "3end"
      elif num == 1:
        word = "5end"
      else:
        word = "offset_{offset_value}"
    else:
      word = ""
    if re.search(r"\S", blacklist):
      word = word + "_BL"
    message = word + scaleFactor
    return " ".join(message.split())

NORMS = _get_normtype(CMD_PARAMS["bamCoverage"],NORM,CMD_PARAMS["bamCoverageBL"])

def _get_matrixtype(normUsing, computeMatrix,genelist):
    if genelist != "":
      genelist = "_" + genelist
    if normUsing != "":
      normUsing = "_" + normUsing
    matchu = re.search(r"--upstream (\w+)", computeMatrix)
    if matchu:
      value = int(matchu.group(1))
      result = str(value / 1000) + "k_"
    else:
      result = "0k_"
    matchu5 = re.search(r"--unscaled5prime (\w+)", computeMatrix)
    if matchu5:
      value = int(matchu5.group(1))
      result = result + str(value / 1000) + "k_"
    matchb = re.search(r"--regionBodyLength (\w+)", computeMatrix)
    if matchb:
      value = int(matchb.group(1))
      result = result + str(value / 1000) + "k_"
    matchu3 = re.search(r"--unscaled3prime (\w+)", computeMatrix)
    if matchu3:
      value = int(matchu3.group(1))
      result = result + str(value / 1000) + "k_"
    matchd = re.search(r"--downstream (\w+)", computeMatrix)
    if matchd:
      value = int(matchd.group(1))
      result = result + str(value / 1000) + "k_"
    matchbin = re.search(r"--binSize (\w+)", computeMatrix)
    if matchbin:
      value = matchbin.group(1)
      result = result + value + "bin"
    else:
      result = result + "0bin"
    message = result + normUsing + genelist
    return message

NORM5S  = _get_matrixtype(NORMS,CMD_PARAMS["reference5"],GENELIST)
NORM5A  = _get_matrixtype(NORMS,CMD_PARAMS["reference5a"],GENELIST)
NORM543 = _get_matrixtype(NORMS,CMD_PARAMS["region543"],GENELIST)
NORM3   = _get_matrixtype(NORMS,CMD_PARAMS["reference3"],GENELIST)

def _get_bampath(bampath):
    if bampath == "subsample":
        word = "bams_sub"
    else:
        word = "bams"
    return word

BAM_PATH = _get_bampath(NORM)

# Final output files
rule all:
    input:
        # bamCoverage
        PROJ + "/URLS/" + PROJ + "_" + INDEX_SAMPLE + "_" + NORMS + "_bw_URL.txt",
        
        # 5 sense matrix file
        PROJ + "/URLS/5_" + PROJ + "_" + INDEX_SAMPLE + "_" + NORM5S + "_sense_matrix.url.txt",
        
        # 5 antisense matrix file
        PROJ + "/URLS/5_" + PROJ + "_" + INDEX_SAMPLE + "_" + NORM5A + "_antisense_matrix.url.txt",
        
        # 543 matrix file
        #PROJ + "/URLS/543_" + PROJ + "_" + INDEX_SAMPLE + "_" + NORM543 + "_sense_matrix.url.txt",
        
        # 3 matrix file
        PROJ + "/URLS/3_" + PROJ + "_" + INDEX_SAMPLE + "_" + NORM3 + "_sense_matrix.url.txt",
        
        # matrix heatmap results
        PROJ + "/" + PROJ + "_" + INDEX_SAMPLE + "_heatmap_analysis.html"



# BW with deeptools bamCoverage
include: "rules/04_bamCoverage_stranded_nogroup.snake"
# 5 sense matrix file
include: "rules/05_5_matrix_sense.snake"
# 5 antisense matrix file
include: "rules/05_5_matrix_antisense.snake"
# 543 matrix file
include: "rules/05_543_matrix_sense.snake"
# 3 matrix file
include: "rules/05_3_matrix_sense.snake"
# heatmap output
include: "rules/06_matrix_heatmap.snake"
include: "rules/07_results_heatmap.snake"
