
```{r "qc setup"}

# Summary files
stats_dir <- here::here(res_dir, "stats/")

fq_sum     <- str_c(stats_dir, proj, "_fastqc.tsv")
trim_sum   <- str_c(stats_dir, proj, "_clumpify.tsv")
bbduk_sum  <- str_c(stats_dir, proj, "_bbduk.tsv")
bwt_sum    <- str_c(stats_dir, proj, "_aligned.tsv")

# Sample names and groups
qc_sams <- lapply(plot_grpss$SAMPLES[[1]], function(x) unlist(x)) %>% bind_cols() 


# Create table of sample groups
# mutate(sample = str_remove(sample, str_c("-", grp)))
grp_key <- qc_sams %>%
  imap_dfr(~ crossing(grp = .y, sample = .x))

# QC theme
qc_theme <- theme(
  panel.border = element_blank(),
  axis.line    = element_line(color = "black", linewidth = ln_pt)
)

```

## FastQC

`FastQC` was used to assess the quality of each fastq file. A summary of the results is shown below.

```{r "fq summary", fig.width = 24, fig.height = 9}

# Some sample names are missing part of the fastq file name
# need to match samples with fastq files
fq_sum <- fq_sum %>%
  read_tsv(col_names = c("value", "metric", "sample"),show_col_types = FALSE) 

fq_sum <- fq_sum %>% 
  mutate(sample = sapply(sample, function(x) grp_key$sample[str_starts(x,grp_key$sample)][1])) %>%
  full_join(grp_key, by = c("sample"))

fq_sum <- fq_sum %>%
  mutate(
    value = fct_relevel(value, distinct(fq_sum,value)$value),
    grp   = fct_relevel(grp, unique(grp_key$grp))
  )

# Create tiles
fq_sum %>%
  ggplot(aes(sample, metric, fill = value)) +
  geom_tile(color = "white", size = 0.5) +
  facet_wrap(~ grp, scales = "free_x", nrow = 2) +
  scale_fill_manual(values = theme_colors[c(3, 4, 2)]) +
  theme_info +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    axis.title   = element_blank(),
    axis.text.x  = element_text(size = 8, angle = 45, hjust = 1, vjust = 1)
  ) +
  qc_theme



```

<br>

## bbtools clumpify and bbduk

`Clumpify` was used to remove duplicate sequences. `Bbduk` was used to remove Illumina sequences

```{r "bbtools summary", fig.width = 16, fig.height = 10}

# bbtools stats
mets <- c(
  "Reads_passing_filters",
  "Duplicates_Removed",
  "Illumina_Seq_Removed"
)

trim_sum <- read_tsv(trim_sum, col_names = c("sample", "metric", "value"),show_col_types = FALSE)

bbduk_sum <- read_tsv(bbduk_sum, col_names = c("sample", "metric", "value"),show_col_types = FALSE) %>% 
  separate(.,value,c("value","temp"),"\\(",extra="drop",fill="right",convert=T) %>% 
  dplyr::select(-temp) 

tb_sum <- bind_rows(trim_sum,bbduk_sum)
tb_sum <- tb_sum  %>% 
  pivot_wider(names_from = "metric", values_from = "value") %>% 
  dplyr::mutate(Reads_passing_filters = `Reads_In` - (`Duplicates_Found` + `Total_Removed`)) %>%
  dplyr::rename(Illumina_Seq_Removed = Total_Removed, Duplicates_Removed = Duplicates_Found ) %>% 
  dplyr::select(-`Reads_In`) %>%
  pivot_longer(cols = -sample, names_to = "metric")


# Create bar graphs
tb_sum %>%
  create_qc_bars(
    grp_df     = grp_key,
    grp_lvls   = names(qc_sams),
    sam_lvls   = NULL,
    met_lvls   = mets,
    plot_cols  = theme_colors,
    lab_metric = "Reads_passing_filters",
    n_rows     = 2
  ) +
  qc_theme

```


<br>

## Read alignment

`Bowtie2` was used to align reads, metrics are shown below. The number of aligned reads (aligned exactly 1 time + aligned >1 times) is displayed on each bar.

```{r "bwt summary", fig.width = 16, fig.height = 10}

# Bowtie2 stats
mets <- c(
  "aligned exactly 1 time",
  "aligned >1 times",
  "aligned 0 times"
)

bwt_sum <- bwt_sum %>%
  read_tsv(col_names = c("sample", "metric", "value"),show_col_types = FALSE) %>%
  dplyr::mutate(metric=str_remove(metric,"concordantly ")) %>% 
  dplyr::filter(metric %in% mets) %>%
  dplyr::mutate(value = as.numeric(value))

# Create bar graphs
bwt_sum %>%
  create_qc_bars(
    grp_df     = grp_key,
    grp_lvls   = names(qc_sams),
    sam_lvls   = NULL,
    met_lvls   = rev(mets),
    plot_cols  = theme_colors[c(2, 5, 4)],
    lab_metric = c("aligned exactly 1 time", "aligned >1 times"),
    n_rows     = 2
  ) +
  qc_theme

```



## fragment size plots

```{r "fragment size plots", fig.width = 16, fig.height = 10}

chunkSize <- 2
pngFiles <- list.files(path = stats_dir, pattern = "*_fragmentSize.png$")
if(length(pngFiles)>0){
  pngFiles <- str_c(stats_dir, pngFiles)
  nsize <- length(pngFiles)
  for(i in 1:ceiling(nsize / chunkSize)){  
    rl = lapply(sprintf(pngFiles[((i-1)*chunkSize+1):min(nsize,(i*chunkSize))]), png::readPNG)
    gl = lapply(rl, grid::rasterGrob)
    gridExtra::grid.arrange(grobs=gl,ncol=chunkSize)
  }

}

```


---

<br>

<br>
