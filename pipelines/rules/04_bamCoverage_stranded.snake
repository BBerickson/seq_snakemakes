# ====== Rules for aligning reads with bamCoverage and OR norm to spike in =================================


# Align trimmed reads with bamCoverage
rule bamCoverage:
    input:
        bam = lambda wildcards: expand(
            PROJ + "/" + BAM_PATH + "/{sample}_aligned_{index}_" + SEQ_DATE + ".bam",
            sample = SAMPLES[wildcards.newnam],
            index = [wildcards.index]
        ),
        check_point = PROJ + "/report/" + PROJ + "_results.tsv"
    output:
        fw      =   PROJ   + "/bw/{newnam}_aligned_{index}_" + SEQ_DATE + "_norm_{suffix}_fw.bw",
        rev     =   PROJ   + "/bw/{newnam}_aligned_{index}_" + SEQ_DATE + "_norm_{suffix}_rev.bw"
    params:
        job_name = "{newnam}_aligned_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage",
        args     = CMD_PARAMS["bamCoverage"] + CMD_PARAMS.get("bamCoverageBL", ""),
        argsf    = _get_bamCov_strand("forward",ORIENTATION),
        argsr    = _get_bamCov_strand("reverse",ORIENTATION)
    resources:
        memory   = lambda wildcards, input: memory_estimator(input.bam, 0.2, 5)
    log:
        out = PROJ + "/logs/{newnam}_aligned_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage.out",
        err = PROJ + "/logs/{newnam}_aligned_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage.err"
    threads: 
        12
    run:
        scale = _get_norm(DF_SAM_NORM, wildcards.newnam, wildcards.suffix, wildcards.index)
        # R2-R1 or R1-R2 ORIENTATION
        shell(f"""
            bamCoverage \
              -b {input.bam[0]} \
              -of bigwig \
              -o {output.fw} \
              {params.args} \
              {scale} \
              -p {threads} \
              --filterRNAstrand {params.argsf}
              
          bamCoverage \
              -b {input.bam[0]} \
              -of bigwig \
              -o {output.rev} \
              {params.args} \
              {scale} \
              -p {threads} \
              --filterRNAstrand {params.argsr}
        """)
  

# Align trimmed reads with bamCoverage
rule bamCoverage_URL:
    input:
        fw      =   PROJ   + "/bw/{newnam}_aligned_{index}_" + SEQ_DATE + "_norm_{suffix}_fw.bw",
        rev     =   PROJ   + "/bw/{newnam}_aligned_{index}_" + SEQ_DATE + "_norm_{suffix}_rev.bw"
    output:
        stats   = temp(PROJ + "/bw/{newnam}_aligned_{index}_" + SEQ_DATE + "_norm_{suffix}_bamCoverage_stats.txt")
    params:
        job_name = "{newnam}_aligned_{index}_" + SEQ_DATE + "_{suffix}_bamCoverageURL",
        color    = lambda wildcards: _get_col(wildcards.newnam, COLS_DICT),
        url_fw   = "http://amc-sandbox.ucdenver.edu/" + USER + "/" + SEQ_DATE + "_" + PROJ + "/{newnam}_aligned_{index}_" + SEQ_DATE + "_norm_{suffix}_fw.bw",
        url_rev  = "http://amc-sandbox.ucdenver.edu/" + USER + "/" + SEQ_DATE + "_" + PROJ + "/{newnam}_aligned_{index}_" + SEQ_DATE + "_norm_{suffix}_rev.bw"
    resources:
        memory   = lambda wildcards, input: memory_estimator(input, 1, 1) # multiplier, min, max, unit=GB
    log:
        out = PROJ + "/logs/{newnam}_aligned_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage_URL.out",
        err = PROJ + "/logs/{newnam}_aligned_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage_URL.err"
    threads: 
        1
    shell:
        """
        echo "track type=bigWig visibility=full name='{wildcards.newnam}_{SEQ_DATE}_{wildcards.suffix}_fw' description='{wildcards.newnam}_{SEQ_DATE}_{wildcards.suffix}_fw' color={params.color} bigDataUrl={params.url_fw}" > {output.stats}
        echo "track type=bigWig visibility=full name='{wildcards.newnam}_{SEQ_DATE}_{wildcards.suffix}_rev' description='{wildcards.newnam}_{SEQ_DATE}_{wildcards.suffix}_rev' color={params.color} bigDataUrl={params.url_rev}" >> {output.stats}
        ssh amc-sandbox 'mkdir -p ./public_html/{SEQ_DATE}_{PROJ}'
        scp {input.fw} amc-sandbox:./public_html/{SEQ_DATE}_{PROJ}
        scp {input.rev} amc-sandbox:./public_html/{SEQ_DATE}_{PROJ}
        
        """


# Combine bamCoverage summaries
rule bamCoverage_summary:
    input:
        lambda wildcards: sorted([
            PROJ + f"/bw/{newnam}_aligned_{index}_{SEQ_DATE}_norm_{suffix}_bamCoverage_stats.txt"
            for newnam, index, suffix in zip(DF_SAM_NORM['Newnam'], DF_SAM_NORM['Index'], DF_SAM_NORM['Suffix'])
            if index == wildcards.index
        ])
    output:
        PROJ + "/URLS/" + PROJ + "_{index}_" + SEQ_DATE + "_norm_{suffix}_bw_URL.txt"
    params:
        job_name = PROJ + "_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage_summary"
    resources:
        memory   = lambda wildcards, input: memory_estimator(input, 1, 1) # multiplier, min, max, unit=GB
    log:
        out = PROJ + "/logs/" + PROJ + "_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage_summary.out",
        err = PROJ + "/logs/" + PROJ + "_{index}_" + SEQ_DATE + "_{suffix}_bamCoverage_summary.err"
    threads:
        1
    run:
        with open(output[0], "w") as out:
            for file in input:
                for line in open(file, "r"):
                    out.write(line)

